{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CWHofBmuf_2c"
   },
   "source": [
    "# HPC Exercices\n",
    "# **Please start this notebook with GPU support, as you will need it later in the exercise. You can change this by going to `Runtime -> Change runtime type -> T4 GPU`**\n",
    "## In this series of exercises, you'll get to compare a few different techniques on accelerated computing that was shown in the lecture. We start by downloading the simulated sales data from the webshop dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u6kA6skbf0BN",
    "outputId": "6c8b8237-e064-4f4f-89e1-690293a1a315"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1xWAK9ruxl9C9SHNFV09oEasnEWhLcvWZ\n",
      "To: /content/sales_data.parquet\n",
      "100% 79.4M/79.4M [00:01<00:00, 75.4MB/s]\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (0.58.1)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba) (0.41.1)\n",
      "Requirement already satisfied: numpy<1.27,>=1.22 in /usr/local/lib/python3.10/dist-packages (from numba) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "# Download sales data\n",
    "!gdown 1xWAK9ruxl9C9SHNFV09oEasnEWhLcvWZ\n",
    "\n",
    "# Install numba\n",
    "!pip install numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7KMP98zhVZC"
   },
   "source": [
    "Let's now extract the item prices and the order totals as two seperate numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xD0mDgmVhfsy"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "item_price = np.array(pd.read_parquet('sales_data.parquet')['item_price'])\n",
    "order_total = np.array(pd.read_parquet('sales_data.parquet')['order_total'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9p4ZmntGibH6"
   },
   "source": [
    "We want to compare the execution times of a few methods shown in the lecture. The quantity we want to calculate as fast as possible is the _item price percentage_ i.e the percentage each items' price fills of the order total. A simple for-loop that calculates this quantity is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NuyBJ4Nshsla"
   },
   "outputs": [],
   "source": [
    "def stupid_python_loop(item_price, order_total):\n",
    "  \"Calculate the percentage that each item fills in the order total\"\n",
    "  result = np.zeros(item_price.shape)\n",
    "  for row in range(len(item_price)):\n",
    "    result[row] = (item_price[row]/order_total[row])*100\n",
    "  return result\n",
    "\n",
    "percentages = stupid_python_loop(item_price, order_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hrAYgUFmiUDt",
    "outputId": "59c8dfd1-1689-4684-dc3a-6b3025cf9312"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.11111013, 34.81997645, 13.97132363, ..., 11.84896251,\n",
       "       10.54651084, 23.53581838])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKwkhUmPi1jl"
   },
   "source": [
    "# **Exercise 1.1**:\n",
    "## use `%timeit -n 10` to profile the execution time of `stupid_python_loop`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ziU3PTNjL2q",
    "outputId": "8d471665-c9f1-4fd6-d53a-a0e01c27468f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2 s ± 140 ms per loop (mean ± std. dev. of 7 runs, 2 loops each)\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION BY RASMUS\n",
    "%timeit -n 2 stupid_python_loop(item_price, order_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ted3yKdIj2Li"
   },
   "source": [
    "# **Exercise 1.2**:\n",
    "## We now want to compare the execution time above with a version of the for-loop that has been altered such that it is JIT-compiled using NUMBA.\n",
    "\n",
    "## Write a version of `stupid_python_loop` that uses the `numba.jit` decorator, and use `%timeit -n 20` to profile the execution time. Name this function `python_loop_jit` How many times is it faster than the original version?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FKd8DNSOj1aE",
    "outputId": "69e127d1-771b-40ec-99ac-8f9df9eaa049"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-e4660949a6f9>:5: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def python_loop_jit(item_price, order_total):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.29 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10.7 ms ± 7 ms per loop (mean ± std. dev. of 7 runs, 20 loops each)\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION BY RASMUS\n",
    "import numba\n",
    "\n",
    "@numba.jit\n",
    "def python_loop_jit(item_price, order_total):\n",
    "  \"Calculate the percentage that each item fills in the order total\"\n",
    "  result = np.zeros(item_price.shape)\n",
    "  for row in range(len(item_price)):\n",
    "    result[row] = (item_price[row]/order_total[row])*100\n",
    "  return result\n",
    "\n",
    "%timeit -n 20 python_loop_jit(item_price, order_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iCFVQ7qllwSl"
   },
   "outputs": [],
   "source": [
    "# 1.63 s -> 1630 ms  -> 1630 ms/8.97 ms =~ 183 times faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dUPsWsOCmRVO"
   },
   "source": [
    "# **Exercise 1.2**:\n",
    "## We now want to compare the execution times from 1.1 and 1.2 with numpy's in-built vectorization method.\n",
    "\n",
    "## Write a version of `stupid_python_loop` that utilizes numpy vectorization instead of loops to calculate the item price percentage. Call this function `python_vectorized` and profile the execution time using `%timeit -n 20`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F0BGN0dymwrR",
    "outputId": "9051fa4e-0820-4f2f-c052-2515442fd1b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.7 ms ± 162 µs per loop (mean ± std. dev. of 7 runs, 20 loops each)\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION BY RASMUS\n",
    "\n",
    "def python_vectorized(item_price, order_total):\n",
    "  return (item_price/order_total) * 100\n",
    "\n",
    "%timeit -n 20 python_vectorized(item_price, order_total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBLheYWungXu"
   },
   "source": [
    "# **Exercise 1.3**:\n",
    "## We now want to compare the execution times from 1.1, 1.2 and 1.3 with a version of the code run by a GPU.\n",
    "\n",
    "## Write a version of `stupid_python_loop` that utilizes numpy vectorization instead of loops to calculate the item price percentage. Call this function `python_vectorized` and profile the execution time using `%timeit -n 20`\n",
    "\n",
    "## Does it matter for the execution time whether the factor `100` is on GPU or CPU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hc1Az4ADoglI",
    "outputId": "b81391c4-fd5c-45d2-8fc7-7c4f4072c5e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 2341.94 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "5.2 ms ± 12.7 ms per loop (mean ± std. dev. of 7 runs, 20 loops each)\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION BY RASMUS\n",
    "\n",
    "import cupy as cp\n",
    "\n",
    "def python_gpu(item_price, order_total):\n",
    "  return item_price/order_total\n",
    "\n",
    "item_price_gpu = cp.array(item_price)\n",
    "order_total_gpu = cp.array(order_total)\n",
    "\n",
    "\n",
    "%timeit -n 20 python_gpu(item_price_gpu, order_total_gpu)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
