{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# HPC Exercices\n",
        "# **Please start this notebook with GPU support, as you will need it later in the exercise. You can change this by going to `Runtime -> Change runtime type -> T4 GPU`**\n",
        "## In this series of exercises, you'll get to compare a few different techniques on accelerated computing that was shown in the lecture. We start by downloading the simulated sales data from the webshop dataset:"
      ],
      "metadata": {
        "id": "CWHofBmuf_2c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6kA6skbf0BN",
        "outputId": "6c8b8237-e064-4f4f-89e1-690293a1a315"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1xWAK9ruxl9C9SHNFV09oEasnEWhLcvWZ\n",
            "To: /content/sales_data.parquet\n",
            "100% 79.4M/79.4M [00:01<00:00, 75.4MB/s]\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (0.58.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba) (0.41.1)\n",
            "Requirement already satisfied: numpy<1.27,>=1.22 in /usr/local/lib/python3.10/dist-packages (from numba) (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "# Download sales data\n",
        "!gdown 1xWAK9ruxl9C9SHNFV09oEasnEWhLcvWZ\n",
        "\n",
        "# Install numba\n",
        "!pip install numba"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now extract the item prices and the order totals as two seperate numpy arrays:"
      ],
      "metadata": {
        "id": "m7KMP98zhVZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "item_price = np.array(pd.read_parquet('sales_data.parquet')['item_price'])\n",
        "order_total = np.array(pd.read_parquet('sales_data.parquet')['order_total'])"
      ],
      "metadata": {
        "id": "xD0mDgmVhfsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to compare the execution times of a few methods shown in the lecture. The quantity we want to calculate as fast as possible is the _item price percentage_ i.e the percentage each items' price fills of the order total. A simple for-loop that calculates this quantity is shown below:"
      ],
      "metadata": {
        "id": "9p4ZmntGibH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stupid_python_loop(item_price, order_total):\n",
        "  \"Calculate the percentage that each item fills in the order total\"\n",
        "  result = np.zeros(item_price.shape)\n",
        "  for row in range(len(item_price)):\n",
        "    result[row] = (item_price[row]/order_total[row])*100\n",
        "  return result\n",
        "\n",
        "percentages = stupid_python_loop(item_price, order_total)\n"
      ],
      "metadata": {
        "id": "NuyBJ4Nshsla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "percentages\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrAYgUFmiUDt",
        "outputId": "59c8dfd1-1689-4684-dc3a-6b3025cf9312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3.11111013, 34.81997645, 13.97132363, ..., 11.84896251,\n",
              "       10.54651084, 23.53581838])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exercise 1.1**:\n",
        "## use `%timeit -n 10` to profile the execution time of `stupid_python_loop`.\n"
      ],
      "metadata": {
        "id": "bKwkhUmPi1jl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_ziU3PTNjL2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exercise 1.2**:\n",
        "## We now want to compare the execution time above with a version of the for-loop that has been altered such that it is JIT-compiled using NUMBA.\n",
        "\n",
        "## Write a version of `stupid_python_loop` that uses the `numba.jit` decorator, and use `%timeit -n 20` to profile the execution time. Name this function `python_loop_jit` How many times is it faster than the original version?"
      ],
      "metadata": {
        "id": "ted3yKdIj2Li"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FKd8DNSOj1aE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exercise 1.2**:\n",
        "## We now want to compare the execution times from 1.1 and 1.2 with numpy's in-built vectorization method.\n",
        "\n",
        "## Write a version of `stupid_python_loop` that utilizes numpy vectorization instead of loops to calculate the item price percentage. Call this function `python_vectorized` and profile the execution time using `%timeit -n 20`\n"
      ],
      "metadata": {
        "id": "dUPsWsOCmRVO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F0BGN0dymwrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exercise 1.3**:\n",
        "## We now want to compare the execution times from 1.1, 1.2 and 1.3 with a version of the code run by a GPU.\n",
        "\n",
        "## Write a version of `stupid_python_loop` that utilizes numpy vectorization instead of loops to calculate the item price percentage. Call this function `python_vectorized` and profile the execution time using `%timeit -n 20`\n",
        "\n",
        "## Does it matter for the execution time whether the factor `100` is on GPU or CPU?"
      ],
      "metadata": {
        "id": "wBLheYWungXu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hc1Az4ADoglI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}